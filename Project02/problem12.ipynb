{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the code for problem 1-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "    Given the dataset in DailyPrices.csv, for the stocks SPY, AAPL, and EQIX\n",
    "\n",
    "    A. Calculate the Arithmetic Returns. Remove the mean, such that each series has 0 mean.\n",
    "    Present the last 5 rows and the total standard deviation.\n",
    "    \n",
    "    B. Calculate the Log Returns. Remove the mean, such that each series has 0 mean.\n",
    "    Present the last 5 rows and the total standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arithmetic Returns - Last 5 Rows:\n",
      "                 SPY      AAPL      EQIX\n",
      "Date                                    \n",
      "2024-12-27 -0.011492 -0.014678 -0.006966\n",
      "2024-12-30 -0.012377 -0.014699 -0.008064\n",
      "2024-12-31 -0.004603 -0.008493  0.006512\n",
      "2025-01-02 -0.003422 -0.027671  0.000497\n",
      "2025-01-03  0.011538 -0.003445  0.015745\n",
      "\n",
      "Arithmetic Returns - Total Standard Deviation:\n",
      "SPY     0.008077\n",
      "AAPL    0.013483\n",
      "EQIX    0.015361\n",
      "dtype: float64\n",
      "\n",
      "Log Returns - Last 5 Rows:\n",
      "                 SPY      AAPL      EQIX\n",
      "Date                                    \n",
      "2024-12-27 -0.011515 -0.014675 -0.006867\n",
      "2024-12-30 -0.012410 -0.014696 -0.007972\n",
      "2024-12-31 -0.004577 -0.008427  0.006602\n",
      "2025-01-02 -0.003392 -0.027930  0.000613\n",
      "2025-01-03  0.011494 -0.003356  0.015725\n",
      "\n",
      "Log Returns - Total Standard Deviation:\n",
      "SPY     0.008078\n",
      "AAPL    0.013446\n",
      "EQIX    0.015270\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('DailyPrices.csv', parse_dates=['Date'], index_col='Date')\n",
    "stocks = ['SPY', 'AAPL', 'EQIX']\n",
    "arithmetic_returns = df[stocks].pct_change().dropna()\n",
    "arithmetic_returns = arithmetic_returns - arithmetic_returns.mean()\n",
    "\n",
    "log_returns = np.log(df[stocks] / df[stocks].shift(1)).dropna()\n",
    "log_returns = log_returns - log_returns.mean()\n",
    "print(\"Arithmetic Returns - Last 5 Rows:\")\n",
    "print(arithmetic_returns.tail())\n",
    "print(\"\\nArithmetic Returns - Total Standard Deviation:\")\n",
    "print(arithmetic_returns.std())\n",
    "\n",
    "print(\"\\nLog Returns - Last 5 Rows:\")\n",
    "print(log_returns.tail())\n",
    "print(\"\\nLog Returns - Total Standard Deviation:\")\n",
    "print(log_returns.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Given the dataset in DailyPrices.csv, you have a portfolio of\n",
    "\n",
    "    ● 100 shares of SPY\n",
    "    ● 200 shares of AAPL\n",
    "    ● 150 shares of EQIX\n",
    "A. Calculate the current value of the portfolio given today is 1/3/2025\n",
    "\n",
    "B. Calculate the VaR and ES of each stock and the entire portfolio at the 5% alpha level\n",
    "assuming arithmetic returns and 0 mean return, for the following methods:\n",
    "\n",
    "    a. Normally distributed with exponentially weighted covariance with lambda=0.97\n",
    "    b. T distribution using a Gaussian Copula\n",
    "    c. Historic simulation using the full history.\n",
    "    C. Discuss the differences between the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23502904 0.1932483  0.57172266]\n",
      "current value for 2025-01-03 is: $251862.50\n"
     ]
    }
   ],
   "source": [
    "date = '2025-01-03'\n",
    "prices = df.loc[date, stocks]\n",
    "portfolio = {'SPY': 100, 'AAPL': 200, 'EQIX': 150}\n",
    "shares=np.array([100, 200, 150])\n",
    "portfolio_value = sum(prices[stock] * portfolio[stock] for stock in stocks)\n",
    "p_weights=np.array([portfolio[stock] * prices[stock] / portfolio_value for stock in stocks])\n",
    "print(p_weights)\n",
    "print(f\"current value for {date} is: ${portfolio_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SPY      AAPL      EQIX\n",
      "SPY   0.000072  0.000054  0.000052\n",
      "AAPL  0.000054  0.000140  0.000038\n",
      "EQIX  0.000052  0.000038  0.000153\n"
     ]
    }
   ],
   "source": [
    "### EWM from Project01, Problem05\n",
    "data_1=arithmetic_returns.drop(arithmetic_returns.columns[0], axis=1)\n",
    "\n",
    "lambda_1= 0.97\n",
    "\n",
    "# weight_list\n",
    "\n",
    "\n",
    "def weight_t_i(i):\n",
    "    global lambda_1\n",
    "    return (1-lambda_1)*lambda_1**(i)\n",
    "\n",
    "def weight_list(len):\n",
    "    weights =[]\n",
    "    for i in range(1, len+1):\n",
    "        weights.append(weight_t_i(len-i))\n",
    "    weights=np.array(weights)\n",
    "    weights=weights/np.sum(weights)\n",
    "    return weights\n",
    "\n",
    "weights=weight_list(len(data_1))\n",
    "\n",
    "\n",
    "def ewcov(data1, data2):\n",
    "    global weigthts\n",
    "    data1 = data1.dropna()\n",
    "    data2 = data2.dropna()\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    data2 = data2.reset_index(drop=True)\n",
    "    data1 = data1.to_numpy()\n",
    "    data2 = data2.to_numpy()\n",
    "    data1 = data1.flatten()\n",
    "    data2 = data2.flatten()\n",
    "    len_data1 = len(data1)\n",
    "    len_data2 = len(data2)\n",
    "    if len_data1 != len_data2:\n",
    "        print('data1 and data2 have different length')\n",
    "        return\n",
    "\n",
    "    mean1 = np.mean(data1)\n",
    "    mean2 = np.mean(data2)\n",
    "    return (data1-mean1) @ np.diag(weights) @ (data2-mean2)\n",
    "\n",
    "\n",
    "def out_ewm(data):\n",
    "    init_cov=data.cov()\n",
    "    for i in init_cov.columns:\n",
    "        for j in init_cov.columns:\n",
    "            init_cov.loc[j,i] = ewcov(data[i], data[j])\n",
    "    return init_cov\n",
    "\n",
    "evm_cov=out_ewm(arithmetic_returns)\n",
    "print(evm_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                VaR  $  Expected Shortfall  $\n",
      "Portfolio  3856.321669            4835.982950\n",
      "SPY         827.848763            1038.155747\n",
      "AAPL        946.076369            1186.417935\n",
      "EQIX       2933.512216            3678.742668\n"
     ]
    }
   ],
   "source": [
    "## a.\n",
    "\n",
    "alpha_level=0.05\n",
    "z_alpha=stats.norm.ppf(1-alpha_level)\n",
    "portfolio_mean=0\n",
    "portfolio_std=np.sqrt(p_weights.T @ evm_cov @ p_weights)\n",
    "VaR=z_alpha*portfolio_std*portfolio_value\n",
    "ES=portfolio_std*stats.norm.pdf(z_alpha)*portfolio_value/alpha_level\n",
    "results = pd.DataFrame(columns=['VaR  $', 'Expected Shortfall  $'])\n",
    "results.loc['Portfolio'] = [VaR, ES]\n",
    "for stock in stocks:\n",
    "    stock_var = z_alpha * np.sqrt(evm_cov.loc[stock, stock]) * portfolio[stock] * prices[stock]\n",
    "    stock_es = np.sqrt(evm_cov.loc[stock, stock]) * portfolio[stock] * prices[stock] * stats.norm.pdf(z_alpha) / alpha_level\n",
    "    results.loc[stock] = [stock_var, stock_es]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VaR 5% $  Expected Shortfall 5% $\n",
      "Portfolio  4370.396952              6015.125106\n",
      "SPY         776.069970              1029.625609\n",
      "AAPL       1060.162802              1508.531772\n",
      "EQIX       3394.449844              4774.627478\n"
     ]
    }
   ],
   "source": [
    "## b.\n",
    "## given a vector of SPY AAPL and EQIX returns, fit into T -distribution\n",
    "## Step 1: map the vector through the T-distribution CDF to (0,1);\n",
    "## Step 2: map the (0,1) using the normal quantile function\n",
    "## Step 3: Using spearman rank correlation to get the correlation matrix\n",
    "## Step 4: Using the correlation matrix to simulate.\n",
    "\n",
    "\n",
    "t_params={}\n",
    "for stock in stocks:\n",
    "    t_params[stock]=stats.t.fit(arithmetic_returns[stock],method='mle')\n",
    "U=pd.DataFrame()\n",
    "for stock in stocks:\n",
    "    df,loc,scale=t_params[stock]\n",
    "    U[stock]=stats.t.cdf(arithmetic_returns[stock], df, loc, scale)\n",
    "normal_quantile=U.apply(lambda x: stats.norm.ppf(x))\n",
    "spearman_rank=normal_quantile.corr(method='spearman')\n",
    "np.random.seed(123)\n",
    "n_samples=10000\n",
    "copula_sim =stats.multivariate_normal.rvs(mean=np.zeros(3), cov=spearman_rank, size=n_samples)\n",
    "sim_returns=np.zeros_like(copula_sim)\n",
    "for i, stock in enumerate(stocks):\n",
    "    df,loc,scale=t_params[stock]\n",
    "    sim_returns[:,i]=stats.t.ppf(stats.norm.cdf(copula_sim[:,i]), df, loc, scale)\n",
    "sim_port_t=sim_returns @ np.diag(prices) @ np.diag(shares)\n",
    "sim_sum_t=sim_port_t.sum(axis=1)\n",
    "var_5_t=-np.percentile(sim_sum_t, 5)\n",
    "ES_5_t=-np.mean(sim_sum_t[sim_sum_t<=-var_5_t])\n",
    "\n",
    "results_t=pd.DataFrame(columns=['VaR 5% $', 'Expected Shortfall 5% $'])\n",
    "results_t.loc['Portfolio']=[var_5_t,ES_5_t]\n",
    "for i, stock in enumerate(stocks):\n",
    "    stock_t=sim_port_t[:,i]\n",
    "    stock_var_t=-np.percentile(stock_t, 5)\n",
    "    stock_es_t=-np.mean(stock_t[stock_t<=-stock_var_t])\n",
    "    results_t.loc[stock]=[stock_var_t,stock_es_t]\n",
    "print(results_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VaR 5% $  Expected Shortfall 5% $\n",
      "Portfolio  4575.034060              6059.387076\n",
      "SPY         872.403863              1080.104204\n",
      "AAPL       1067.114956              1437.785272\n",
      "EQIX       3635.077091              4714.893996\n"
     ]
    }
   ],
   "source": [
    "## c. Directly use the history as the simulation\n",
    "## make N random draws( rows) from the historical data (arithmetic_returns)\n",
    "sim_returns_his=arithmetic_returns\n",
    "sim_port_his=sim_returns_his @ np.diag(prices) @ np.diag(shares)  \n",
    "sim_port_his.columns=stocks\n",
    "sim_sum_his=sim_port_his.sum(axis=1)\n",
    "var_5_his=-np.percentile(sim_sum_his, 5)\n",
    "ES_5_his=-np.mean(sim_sum_his[sim_sum_his<=-var_5_his])\n",
    "results_his=pd.DataFrame(columns=['VaR 5% $', 'Expected Shortfall 5% $'])\n",
    "results_his.loc['Portfolio']=[var_5_his,ES_5_his]\n",
    "for i, stock in enumerate(stocks):\n",
    "    stock_his=sim_port_his[stock]\n",
    "    stock_var_his=-np.percentile(stock_his, 5)\n",
    "    stock_es_his=-np.mean(stock_his[stock_his<=-stock_var_his])\n",
    "    results_his.loc[stock]=[stock_var_his,stock_es_his]\n",
    "\n",
    "print(results_his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n    Here goes the comparison of the three methods.\\n    \\n    Method 1: EWM, it generates the least loss, maybe because it assumes a more ideal nora distribution condition. \\n             It calcultes the covariance matrix using the EWM method, which is more sensitive to the recent data.\\n    Method 2: T-distribution, it generates a result similar to historical simulation.\\n    Method 3: Historical simulation, it simple uses history data without any modeling to estimate the var and risk.\\n    \\n    There are many minor differences between method 2 and method 3, because they are mainly uniform based on the same\\n    data scope. Yet the ewm is a lot different because it focuses more on the recent data. I would say that the ewm method\\n    is something that is constructive and cutting edge, simply because a different focus.\\n    \\n    Maybe fitting copulas using ewm method instead of spearman rank correlation could generate some interesting results.\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## C. Compare the methods\n",
    "'''  \n",
    "    Here goes the comparison of the three methods.\n",
    "    \n",
    "    Method 1: EWM, it generates the least loss, maybe because it assumes a more ideal nora distribution condition. \n",
    "             It calcultes the covariance matrix using the EWM method, which is more sensitive to the recent data.\n",
    "    Method 2: T-distribution, it generates a result similar to historical simulation.\n",
    "    Method 3: Historical simulation, it simple uses history data without any modeling to estimate the var and risk.\n",
    "    \n",
    "    There are many minor differences between method 2 and method 3, because they are mainly uniform based on the same\n",
    "    data scope. Yet the ewm is a lot different because it focuses more on the recent data. I would say that the ewm method\n",
    "    is something that is constructive and cutting edge, simply because a different focus.\n",
    "    \n",
    "    Maybe fitting copulas using ewm method instead of spearman rank correlation could generate some interesting results.\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
